# 环境变量示例文件
# 复制此文件为 .env 并填写实际值

# AWS S3配置
AWS_ACCESS_KEY_ID=your_access_key_id
AWS_SECRET_ACCESS_KEY=your_secret_access_key
S3_BUCKET_NAME=your_bucket_name
S3_REGION=us-east-1

# 七牛云S3兼容模式配置
# 使用方式：在config.yaml中设置 type: "s3" 和 endpoint_url
# 七牛云各区域endpoint示例：
#   华东-浙江: https://s3.cn-east-1.qiniucs.com (region: cn-east-1)
#   华东-上海: https://s3.cn-east-2.qiniucs.com (region: cn-east-2)
#   华北: https://s3.cn-north-1.qiniucs.com (region: cn-north-1)
#   华南: https://s3.cn-south-1.qiniucs.com (region: cn-south-1)
#   北美: https://s3.us-north-1.qiniucs.com (region: us-north-1)
#   东南亚: https://s3.as-south-1.qiniucs.com (region: as-south-1)
# 注意：七牛云的AccessKey和SecretKey可以当作AWS的access_key_id和secret_access_key使用
QINIU_ACCESS_KEY=your_qiniu_access_key
QINIU_SECRET_KEY=your_qiniu_secret_key
QINIU_BUCKET_NAME=your_bucket_name
QINIU_ENDPOINT=https://s3.cn-east-1.qiniucs.com
QINIU_REGION=cn-east-1

# ======================================================================
# 数据库配置（支持 MySQL、PostgreSQL）
# ======================================================================
# 注：Supabase 本质就是 PostgreSQL，直接使用 DB_TYPE=postgresql

# 数据库类型选择（mysql, postgresql）
DB_TYPE=mysql

# --- MongoDB 配置 ---
MONGODB_URI=mongodb://localhost:27017/crawler_db

# --- MySQL 配置 ---
# 方式1：使用完整URI（推荐）
MYSQL_URI=mysql+pymysql://root:password@localhost:3306/crawler_db

# 方式2：分别配置各项（如果没有设置 MYSQL_URI，则使用以下配置）
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_USER=root
MYSQL_PASSWORD=password
MYSQL_DATABASE=crawler_db
MYSQL_CHARSET=utf8mb4
MYSQL_SSL_DISABLED=false

# --- PostgreSQL 配置（包括本地 PostgreSQL 和 Supabase）---
#
# 方式1：使用完整 URI（推荐）
#
# 本地 PostgreSQL：
# POSTGRESQL_URI=postgresql://postgres:password@localhost:5432/property_search
#
# Supabase（托管 PostgreSQL）：
# ⚠️ 重要：必须使用 Connection Pooling 连接（支持 IPv4）
#          不要使用 Direct Connection（仅支持 IPv6）
# 从 Supabase Dashboard → Project Settings → Database → Connection String
# → 选择 "Connection pooling" 标签 → 复制
# POSTGRESQL_URI=postgresql://postgres.{project}:[PASSWORD]@aws-{region}.pooler.supabase.com:5432/postgres
# 示例：
# POSTGRESQL_URI=postgresql://postgres.rlfsvixfbyauygglwsoi:YOUR_PASSWORD@aws-1-ap-southeast-2.pooler.supabase.com:5432/postgres
#
# 方式2：分别配置各项（如果没有设置 POSTGRESQL_URI，则使用以下配置）
PG_HOST=localhost
PG_PORT=5432
PG_USER=postgres
PG_PASSWORD=password
PG_DATABASE=property_search
PG_SSL_MODE=prefer

# --- 数据库连接池配置（通用）---
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20

# --- Redis 配置（可选）---
# REDIS_URL=redis://localhost:6379/0

# 地理编码配置
# 注意：启用地理编码会显著降低爬取速度（每个地址需要1秒）
# 建议：先爬取数据，再使用独立脚本进行地理编码（见 scripts/geocode_listings.py）
# 注意：更新模式（update mode）会自动启用地理编码，因为数量少不影响速度
ENABLE_GEOCODING=false  # 爬取时是否启用地理编码（true/false），更新模式会自动启用

# 代理配置
# 动态住宅代理（Bright Data residential proxy - 推荐用于批量爬取和图片处理）
# 每次请求自动切换IP，避免被封禁，适合大规模处理
PROXY_URL=http://brd-customer-hl_xxx-zone-residential_proxy1:your_password@brd.superproxy.io:33335

# SSL证书路径（Bright Data代理需要）
PROXY_SSL_CERT=cert/ca-certificate.crt

# 远程浏览器API配置（Bright Data Scraping Browser）
BROWSER_AUTH=brd-customer-hl_xxx-zone-scraping_browser1:your_password

# 基于 Puppeteer 的远程浏览器配置
# 支持连接远程 Puppeteer 服务（如 Browserless.io 或自建 Puppeteer 服务）
# 获取 WebSocket 端点的方法：
#   1. 本地 Puppeteer: 启动 Chrome 时使用 --remote-debugging-port=9222
#      然后访问 http://localhost:9222/json 获取 ws://localhost:9222/devtools/browser/xxx
#   2. Browserless.io: 从控制台获取 WebSocket 端点
#   3. 其他 Puppeteer 服务: 参考服务提供商的文档
PUPPETEER_WS_ENDPOINT=ws://localhost:9222/devtools/browser/xxx

# 浏览器类型配置
# 可选值：
#   - remote: 使用远程浏览器（Bright Data Scraping Browser，需要配置 BROWSER_AUTH）
#   - local: 使用本地标准 Chrome 浏览器
#   - undetected: 使用 Undetected Chrome 浏览器（推荐，增强反检测能力）
#   - puppeteer: 使用 Puppeteer 远程浏览器（需要配置 PUPPETEER_WS_ENDPOINT）
BROWSER_TYPE=undetected

# Chrome版本配置（可选，仅 undetected 模式使用）
# 如果不设置，会自动检测系统的Chrome版本
# CHROME_VERSION=120

# ChromeDriver路径（可选，用于非x86架构如ARM64/Raspberry Pi）
# 如果不设置，会自动下载ChromeDriver（仅支持x86_64）
# ARM64系统需要手动指定chromium-driver路径（建议复制到用户目录）
# 安装方法：sudo apt-get install chromium-driver
# 复制到用户目录：cp /usr/bin/chromedriver ~/.local/bin/chromedriver
# CHROMEDRIVER_PATH=/home/your_user/.local/bin/chromedriver

# Chrome/Chromium 浏览器可执行文件路径（可选，用于ARM64/Raspberry Pi）
# ARM64系统使用 Chromium，需要指定浏览器路径
# CHROME_BINARY_PATH=/usr/bin/chromium

# 浏览器无头模式（适用于所有浏览器类型）
# 注意：undetected 模式在无头模式下可能不稳定，推荐使用有头模式或虚拟显示模式
# ARM64/树莓派：建议设为 true（无头模式更快更稳定）
BROWSER_HEADLESS=false

# 虚拟显示模式（仅 undetected 模式，需要安装 xvfb）
# true: 使用虚拟显示，有头模式但不显示窗口（推荐，适合原生 Linux 服务器）
# false: 正常显示窗口（或使用无头模式）
# 注意：WSL2 环境下虚拟显示可能不稳定，建议设为 false 或使用无头模式
# 注意：ARM64/树莓派：建议设为 false（使用无头模式代替）
# 安装方法：sudo apt-get install xvfb && pip install pyvirtualdisplay
BROWSER_USE_VIRTUAL_DISPLAY=false

# 禁用图片和资源加载（提升爬取速度，适用于 undetected 模式）
# true: 禁用图片、CSS、字体等资源加载（推荐，大幅提升速度）
# false: 正常加载所有资源
BROWSER_DISABLE_IMAGES=true

# 代理API配置（动态代理池）
PROXY_API_KEY=your_proxy_api_key
PROXY_API_URL=https://api.proxy-service.com/get

# 直连代理API配置（如熊猫代理等）
# 注意：请求频率限制为1秒1次，IP有效期5分钟
PROXY_DIRECT_API_BASE_URL=http://route.xiongmaodaili.com/xiongmao-web/api/glip
PROXY_DIRECT_SECRET=your_secret_key
PROXY_DIRECT_ORDER_NO=your_order_no
PROXY_DIRECT_COUNT=10
PROXY_DIRECT_PROXY_TYPE=1
PROXY_DIRECT_RETURN_ACCOUNT=2
PROXY_POOL_FILE=proxy_pool.json  # IP池持久化文件（支持中断续用，避免浪费IP）

# 图片去水印API配置 (magiceraser.org)
WATERMARK_REMOVER_PRODUCT_SERIAL=d92a85a2-7f15-40d0-975d-518d1610eb71
WATERMARK_REMOVER_PRODUCT_CODE=067003
WATERMARK_REMOVER_AUTHORIZATION=

# 安全配置
ENCRYPTION_KEY=your_encryption_key_here
API_SECRET_KEY=your_api_secret_key

# 其他配置
DEBUG=False
LOG_LEVEL=INFO
